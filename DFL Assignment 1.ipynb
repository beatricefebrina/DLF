{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c302c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from os.path import join\n",
    "\n",
    "mem = Memory(\"./mycache\")\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "    return save_path\n",
    "\n",
    "@mem.cache\n",
    "def get_data(file_path):\n",
    "    data = load_svmlight_file(file_path)\n",
    "    return data[0], data[1]\n",
    "\n",
    "data = {\n",
    "    \"raw\": \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\",\n",
    "    \"scale\": \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes_scale\"\n",
    "}\n",
    "\n",
    "\n",
    "data_dir = \"/Users/beatricefebrina/Documents/Masters/T3/download\"\n",
    "\n",
    "data_file_paths  = {}\n",
    "download_needed = True\n",
    "     \n",
    "\n",
    "if download_needed:\n",
    "    for k, url in data.items():\n",
    "        r = download_file(url, join(data_dir, f\"diabetes_{k}\"))\n",
    "        data_file_paths[k] = r\n",
    "else:\n",
    "    data_file_paths = {\n",
    "        \"raw\": join(data_dir, \"diabetes_raw\"),\n",
    "        \"scale\": join(data_dir, \"diabetes_scale\")\n",
    "\n",
    "  }\n",
    "     \n",
    "\n",
    "data_store = {}\n",
    "\n",
    "for k, p in data_file_paths.items():\n",
    "    X, y = get_data(p)\n",
    "    data_store[k] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1475708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptrons:\n",
    "    def __init__(self, lr, iteration_num):\n",
    "        self.lr = lr\n",
    "        self.iteration_num = iteration_num\n",
    "\n",
    "    def binary_step(self, x):\n",
    "        return np.where(x >= 0, 1, -1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return np.matmul(self.weight, x) + self.bias\n",
    "\n",
    "    def update(self, x, error):\n",
    "        self.weight = self.weight - x * error * self.lr\n",
    "        self.bias = self.bias - self.lr * error\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.weight = np.random.uniform(low=-1, high=1, size=X.shape[1])\n",
    "        self.bias = np.random.uniform(low=-1, high=1, size=1)\n",
    "\n",
    "        for i in range(self.iteration_num):\n",
    "            for x_, y_ in zip(X, y):\n",
    "                output = self.forward(x_)\n",
    "                y_predict = self.binary_step(output)\n",
    "                error = y_predict - y_\n",
    "                self.update(x_, error)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for x in X:\n",
    "            y_ = self.forward(x)\n",
    "            y_ = self.binary_step(y_[0]) \n",
    "            y.append(y_)\n",
    "        return np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b3b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.82      0.51      0.63        55\n",
      "         1.0       0.78      0.94      0.85        99\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.80      0.72      0.74       154\n",
      "weighted avg       0.79      0.79      0.77       154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.71      0.62      0.66        55\n",
      "         1.0       0.80      0.86      0.83        99\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.76      0.74      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.78      0.64      0.70        55\n",
      "         1.0       0.82      0.90      0.86        99\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.80      0.77      0.78       154\n",
      "weighted avg       0.80      0.81      0.80       154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.55      0.65        55\n",
      "         1.0       0.78      0.92      0.85        99\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.79      0.73      0.75       154\n",
      "weighted avg       0.79      0.79      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# standardization of dependent variables\n",
    "random.seed(42)\n",
    "Xr = preprocessing.scale(data_store[\"scale\"][0].toarray())\n",
    "yr = data_store[\"scale\"][1]\n",
    "\n",
    "random.seed(42)\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.20, random_state=42)\n",
    "\n",
    "lr = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "\n",
    "for i in lr:\n",
    "    random.seed(42)\n",
    "    perceptron1 = Perceptrons(lr=i , iteration_num=70)\n",
    "    perceptron1.fit(Xr_train, yr_train)\n",
    "\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred1 = perceptron1.predict(Xr_test)\n",
    "\n",
    "    # Evaluate the model's performance using standard classification metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    rep = classification_report(yr_test, y_pred1)\n",
    "    print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63899f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.34      0.40       102\n",
      "         1.0       0.72      0.83      0.77       206\n",
      "\n",
      "    accuracy                           0.67       308\n",
      "   macro avg       0.61      0.58      0.59       308\n",
      "weighted avg       0.64      0.67      0.65       308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.62      0.48      0.54       102\n",
      "         1.0       0.77      0.85      0.81       206\n",
      "\n",
      "    accuracy                           0.73       308\n",
      "   macro avg       0.69      0.67      0.68       308\n",
      "weighted avg       0.72      0.73      0.72       308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.62      0.49      0.55       102\n",
      "         1.0       0.77      0.85      0.81       206\n",
      "\n",
      "    accuracy                           0.73       308\n",
      "   macro avg       0.69      0.67      0.68       308\n",
      "weighted avg       0.72      0.73      0.72       308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.64      0.64      0.64       102\n",
      "         1.0       0.82      0.83      0.82       206\n",
      "\n",
      "    accuracy                           0.76       308\n",
      "   macro avg       0.73      0.73      0.73       308\n",
      "weighted avg       0.76      0.76      0.76       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "Xr_train60, Xr_test60, yr_train60, yr_test60 = train_test_split(Xr, yr, test_size=0.40, random_state=42)\n",
    "\n",
    "lr = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "\n",
    "for i in lr:\n",
    "    random.seed(42)\n",
    "    perceptron1 = Perceptrons(lr=i , iteration_num=70)\n",
    "    perceptron1.fit(Xr_train60, yr_train60)\n",
    "\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = perceptron1.predict(Xr_test60)\n",
    "\n",
    "    # Evaluate the model's performance using standard classification metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(yr_test60, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0316881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
